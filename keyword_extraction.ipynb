{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib.request\n",
    "import requests\n",
    "import time\n",
    "from IPy import IP\n",
    "from collections import defaultdict\n",
    "import itertools  #used to slice a dictionary\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions used for extraction of text from the url provided\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def text_from_title(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    title_text = soup.find('title').text\n",
    "    return title_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywordExtractor(url):\n",
    "    url = url.strip()\n",
    "    headers={'User-Agent': 'Mozilla/5.0'}\n",
    "    resp = requests.get(url, headers=headers, timeout=3) \n",
    "    if resp.status_code >= 300:\n",
    "        return\n",
    "    html = resp.text\n",
    "    text = text_from_html(html)\n",
    "    title_text = text_from_title(html).lower()\n",
    "    max_ngram_size = 1\n",
    "    simple_kwextractor = yake.KeywordExtractor(lan=\"en\", n = max_ngram_size, dedupLim=0.9, dedupFunc='seqm', windowsSize=1, top=20, features=None)\n",
    "    keywords = simple_kwextractor.extract_keywords(text)\n",
    "    title_keywords = simple_kwextractor.extract_keywords(title_text)\n",
    "    title_words = dict([(t[1], t[0]) for t in title_keywords])  #to swap the term and its score to get {term:score}\n",
    "    title_words = title_words.keys()\n",
    "    \n",
    "    keywords2 = []\n",
    "    for kw in keywords:\n",
    "        #since the order of term and score is reversed\n",
    "        if kw[1] in title_words:\n",
    "            kw2 = (kw[0]/4, kw[1])\n",
    "        else:\n",
    "            kw2 = kw\n",
    "        keywords2.append(kw2)   #should be inside for loop so that all words are appended\n",
    "    keywords2 = dict([(t[1], t[0]) for t in keywords2]) #to make a dictionary(as given in description) and also to reverse the order to {term:score}\n",
    "    return keywords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://localhost:8888/lab': {'scroll_dist': 0, 'time_spent': 27},\n",
      " 'https://codeforces.com/': {'scroll_dist': 1187.199951171875, 'time_spent': 6},\n",
      " 'https://github.com/kanishk509/Multi-dimensional-graph-based-search-customization': {'scroll_dist': 0,\n",
      "                                                                                      'time_spent': 8},\n",
      " 'https://stackoverflow.com/questions/2260446/how-to-iterate-through-dictionary-and-change-values': {'scroll_dist': 0,\n",
      "                                                                                                     'time_spent': 3},\n",
      " 'https://web.whatsapp.com/': {'scroll_dist': 0, 'time_spent': 4}}\n"
     ]
    }
   ],
   "source": [
    "# load new history created since last update\n",
    "\n",
    "path_history = './data/history.data'\n",
    "\n",
    "try:\n",
    "\twith open(path_history, 'rb') as f:\n",
    "\t\thistory_dict = pickle.load(f)\n",
    "except:\n",
    "\thistory_dict = {}\n",
    "    \n",
    "pprint.pprint(history_dict)\n",
    "    \n",
    "# looks like: \n",
    "# {\n",
    "#     'http://localhost:8888/lab': {'scroll_dist': 0, 'time_spent': 27},\n",
    "    \n",
    "#     'https://codeforces.com/': {'scroll_dist': 1187.199951171875, 'time_spent': 6},\n",
    "    \n",
    "#     'https://github.com/kanishk509/Multi-dimensional-graph-based-search-customization': {'scroll_dist': 0,\n",
    "#                                                                                       'time_spent': 8},\n",
    "    \n",
    "#     'https://stackoverflow.com/questions/2260446/how-to-iterate-through-dictionary-and-change-values': {'scroll_dist': 0,\n",
    "#                                                                                                      'time_spent': 3},\n",
    "    \n",
    "#     'https://web.whatsapp.com/': {'scroll_dist': 0, 'time_spent': 4}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords database structure\n",
    "\n",
    "keywords_db = {\n",
    "    'python' : {\n",
    "        'title'    : 1.0, \n",
    "        'body'     : 1.0, \n",
    "        'bookmark' : 1.0, \n",
    "        'urls'     : ['https://docs.python.org/3/tutorial/index.html', ]\n",
    "    },\n",
    "}\n",
    "\n",
    "#load keywords database from json file\n",
    "\n",
    "filename = \"./data/keywords_db.data\"\n",
    "\n",
    "# try:\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         keywords_db = pickle.load(f)\n",
    "# except:\n",
    "#     keywords_db = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new keywords that we need to add as nodes/add edges for \n",
    "# in our clustering graph.\n",
    "\n",
    "new_keywords_to_cluster = [['a', 'b'], ['c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_history(history_dict):\n",
    "    \n",
    "    for url in history_dict:\n",
    "        url_time = history_dict[url]['time_spent']\n",
    "        url_scroll = history_dict[url]['scroll_dist']\n",
    "        if url_scroll == 0:\n",
    "            # some default value\n",
    "            url_scroll = 100.0\n",
    "\n",
    "        try:\n",
    "            # taking 5 most significant keywords\n",
    "            keywords_list = keywordExtractor(url).items()\n",
    "            keywords_list = sorted(keywords_list, key=lambda key: key[1])\n",
    "            keywords_list = keywords_list[:5]\n",
    "            \n",
    "            # add keywords to be clustered\n",
    "            new_keywords_to_cluster.append(\n",
    "                [word for (word, value) in keywords_list])\n",
    "            \n",
    "            # add code to make new entry for keyword in keyword_db \n",
    "            # or if already present: \n",
    "            #    1) update score\n",
    "            #    2) add url to the keyword's list of urls\n",
    "            \n",
    "            #for kw in keywords[:5]:\n",
    "                # code to update score of keyword\n",
    "                \n",
    "        except:\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_new_history(history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save keywords to cluster\n",
    "with open('./data/to_cluster.data', 'wb') as outfile:\n",
    "    pickle.dump(new_keywords_to_cluster, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save keywords database\n",
    "with open('./data/keyword_db.data', 'wb') as outfile:\n",
    "    pickle.dump(keywords_db, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
